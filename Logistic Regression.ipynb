{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7HsyyRyt-EuC"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Importing the dataset"
      ],
      "metadata": {
        "id": "wuEQ3P4mezEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images , train_labels),(test_images , test_labels) = mnist.load_data() "
      ],
      "metadata": {
        "id": "O6r4AdX6D8ZQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape , train_labels.shape)\n",
        "print(test_images.shape , test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnA1cWi6G48j",
        "outputId": "44c611f2-99fc-49ac-93b6-bc1f28c86eb0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*subset the data to use only class 0 and class1"
      ],
      "metadata": {
        "id": "xb_OhmcUeXEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_indexes = (train_labels==0)|(train_labels==1)\n",
        "test_indexes = (test_labels==0)|(test_labels==1)\n",
        "x_train = train_images[train_indexes]\n",
        "y_train = train_labels[train_indexes]\n",
        "\n",
        "x_test = test_images[test_indexes]\n",
        "y_test = test_labels[test_indexes]\n",
        "\n",
        "#reshape training data\n",
        "x_train = x_train.reshape(-1 , 784)\n",
        "y_train = y_train.reshape(-1 , 1)\n",
        "\n",
        "x_test = x_test.reshape(-1 , 784)\n",
        "y_test = y_test.reshape(-1 , 1)\n"
      ],
      "metadata": {
        "id": "iJnXZG47G6Oy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*standardization of the data"
      ],
      "metadata": {
        "id": "a8g0_X2szYxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_x_train = np.mean(x_train)\n",
        "std_x_train = np.std(x_train)\n",
        "x_train = (x_train - mean_x_train)/std_x_train\n",
        "\n",
        "\n",
        "mean_x_test = np.mean(x_test)\n",
        "std_x_test = np.std(x_test)\n",
        "x_test = (x_test - mean_x_test)/std_x_test"
      ],
      "metadata": {
        "id": "fSIZuHsoswjb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Logistic Regression"
      ],
      "metadata": {
        "id": "6nbVKeGvopHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(X, y, lr, num_iterations):\n",
        "   \n",
        "    m, n = X.shape\n",
        "    w = np.zeros((n, 1))\n",
        "    b = 0\n",
        "    limit = 10 ** -8\n",
        "\n",
        "   \n",
        "    for i in range(num_iterations):\n",
        "        \n",
        "        z = np.dot(X, w) + b\n",
        "        A = 1 / (1 + np.exp(-z))\n",
        "        \n",
        "        # cost function\n",
        "        error = (-1/m) * np.sum(y*np.log(A) + (1-y)*np.log(1-A))\n",
        "        \n",
        "        \n",
        "        dw = np.mean( np.dot(X.T, (A-y)))\n",
        "        db = np.mean( np.sum(A-y))\n",
        "        \n",
        "        # Update parameters\n",
        "        w = w - lr * dw\n",
        "        b = b - lr * db\n",
        "        if (error < limit):\n",
        "          break\n",
        "        \n",
        "    return w, b"
      ],
      "metadata": {
        "id": "JC-c_QvrDKzU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Divide data into training and validation set using 10-fold cross validation method"
      ],
      "metadata": {
        "id": "uU2lUasPI0kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 10\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "accuracies = []\n",
        "# Shuffle the data and labels\n",
        "idx = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "# Split the data and labels into num_folds folds\n",
        "data_folds = np.array_split(x_train, num_folds)\n",
        "labels_folds = np.array_split(y_train, num_folds)\n",
        "\n",
        "for i in range(num_folds):\n",
        "    # Select the i-th fold as the validation set\n",
        "    val_data = data_folds[i]\n",
        "    val_labels = labels_folds[i]\n",
        "    \n",
        "    # Use the remaining folds as training data\n",
        "    train_data_fold = np.concatenate(data_folds[:i] + data_folds[i+1:])\n",
        "    train_labels_fold = np.concatenate(labels_folds[:i] + labels_folds[i+1:])"
      ],
      "metadata": {
        "id": "zfgpvp2JBf2J"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Logistic Regression with different values for learning rate\n",
        "    \n",
        "    \n",
        "\n",
        "for lr in learning_rates:\n",
        "      w, b = logistic_regression(train_data_fold , train_labels_fold.reshape(-1,1), lr, num_iterations=1000)\n",
        "        \n",
        "      # Predict on validation set\n",
        "      z = np.dot(val_data, w) + b\n",
        "      A = 1 / (1 + np.exp(-z))\n",
        "      predictions = (A > 0.5).astype(int)\n",
        "      acc = np.mean(predictions == val_labels .reshape(-1,1))\n",
        "      accuracies.append(acc)\n",
        "      print('Learning rate: {}, Accuracy: {:.2f}'.format(lr, acc))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psxk63MG7lFc",
        "outputId": "3eea5b30-ba6e-4b89-a547-56ba29ab4e6d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-f70b91815a07>:15: RuntimeWarning: divide by zero encountered in log\n",
            "  error = (-1/m) * np.sum(y*np.log(A) + (1-y)*np.log(1-A))\n",
            "<ipython-input-45-f70b91815a07>:15: RuntimeWarning: invalid value encountered in multiply\n",
            "  error = (-1/m) * np.sum(y*np.log(A) + (1-y)*np.log(1-A))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001, Accuracy: 0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-f70b91815a07>:12: RuntimeWarning: overflow encountered in exp\n",
            "  A = 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.01, Accuracy: 0.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-33c7fb3f4f3c>:10: RuntimeWarning: overflow encountered in exp\n",
            "  A = 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.1, Accuracy: 0.93\n",
            "Learning rate: 1, Accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report difference accuracy for the different learning rate\n",
        "acc_diff = np.array(accuracies).reshape(-1, len(learning_rates)).mean(axis=0)\n",
        "for i, lr in enumerate(learning_rates):\n",
        "    print('Learning rate: {}, Average accuracy: {:.2f}'.format(lr, acc_diff[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NUKAFXAGUp3",
        "outputId": "0c4ec52d-1358-4486-9392-34dea17fe15e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001, Average accuracy: 0.93\n",
            "Learning rate: 0.01, Average accuracy: 0.94\n",
            "Learning rate: 0.1, Average accuracy: 0.93\n",
            "Learning rate: 1, Average accuracy: 0.94\n"
          ]
        }
      ]
    }
  ]
}